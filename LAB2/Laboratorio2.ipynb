{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8bbab2",
   "metadata": {},
   "source": [
    "# Laboratorio 2 – Machine Learning  \n",
    "## Complejidad y búsqueda de hiperparámetros – AlpesHearth  \n",
    "\n",
    "### Integrantes:\n",
    "1. Juan Sebastian Rodriguez Torres - 202214617 - js.rodriguezt1@uniandes.edu.co\n",
    "2. Luis Felipe Sales Galviz - 202211531 - l.sales@uniandes.edu.co\n",
    "\n",
    "\n",
    "## Carga de datos:\n",
    "\n",
    "En esta sección vamos a cargar los datos para dejarlo con las modificaciones iniciales realizadas previas al modelado en el LAB 1:\n",
    "Las columnas irrelevantes quedan eliminadas, los registros duplicados, las filas sin variable objetuvo y los \"CVD Risk Score\" menores a 0 y mayores a 100 tambien. Dado que el enfoque ahora está en modelado y validación, no se repetirá el proceso de exploración ni limpieza profunda que se hizo para cada modelo del lab 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a945c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "df_real = pd.read_csv(\"./data/Datos Lab 1.csv\")\n",
    "df = df_real.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f34209f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros con Risk Score nulo eliminados: 29\n",
      "Duplicados eliminados: 261 (quedan 1349)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Height (m)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Abdominal Circumference (cm)</th>\n",
       "      <th>Total Cholesterol (mg/dL)</th>\n",
       "      <th>HDL (mg/dL)</th>\n",
       "      <th>Fasting Blood Sugar (mg/dL)</th>\n",
       "      <th>Smoking Status</th>\n",
       "      <th>Diabetes Status</th>\n",
       "      <th>Physical Activity Level</th>\n",
       "      <th>Family History of CVD</th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Waist-to-Height Ratio</th>\n",
       "      <th>Systolic BP</th>\n",
       "      <th>Diastolic BP</th>\n",
       "      <th>Estimated LDL (mg/dL)</th>\n",
       "      <th>CVD Risk Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>F</td>\n",
       "      <td>52.0</td>\n",
       "      <td>109.700</td>\n",
       "      <td>1.780</td>\n",
       "      <td>34.600</td>\n",
       "      <td>104.400</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.915</td>\n",
       "      <td>99.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>High</td>\n",
       "      <td>N</td>\n",
       "      <td>178.000</td>\n",
       "      <td>0.587</td>\n",
       "      <td>103.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104.469</td>\n",
       "      <td>1.995</td>\n",
       "      <td>25.390</td>\n",
       "      <td>86.894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.000</td>\n",
       "      <td>175.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Low</td>\n",
       "      <td>Y</td>\n",
       "      <td>199.458</td>\n",
       "      <td>0.436</td>\n",
       "      <td>164.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>18.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>M</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.870</td>\n",
       "      <td>33.800</td>\n",
       "      <td>99.600</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6.809</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Low</td>\n",
       "      <td>N</td>\n",
       "      <td>187.000</td>\n",
       "      <td>0.533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>F</td>\n",
       "      <td>52.0</td>\n",
       "      <td>107.800</td>\n",
       "      <td>1.780</td>\n",
       "      <td>34.000</td>\n",
       "      <td>103.500</td>\n",
       "      <td>179.0</td>\n",
       "      <td>73.000</td>\n",
       "      <td>132.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Low</td>\n",
       "      <td>Y</td>\n",
       "      <td>178.000</td>\n",
       "      <td>0.581</td>\n",
       "      <td>111.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>15.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>M</td>\n",
       "      <td>57.0</td>\n",
       "      <td>116.772</td>\n",
       "      <td>1.569</td>\n",
       "      <td>34.126</td>\n",
       "      <td>90.737</td>\n",
       "      <td>254.0</td>\n",
       "      <td>60.000</td>\n",
       "      <td>177.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Low</td>\n",
       "      <td>Y</td>\n",
       "      <td>156.854</td>\n",
       "      <td>0.578</td>\n",
       "      <td>117.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>17.755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex   Age  Weight (kg)  Height (m)     BMI  Abdominal Circumference (cm)  \\\n",
       "675    F  52.0      109.700       1.780  34.600                       104.400   \n",
       "1369   F   NaN      104.469       1.995  25.390                        86.894   \n",
       "774    M  58.0          NaN       1.870  33.800                        99.600   \n",
       "1044   F  52.0      107.800       1.780  34.000                       103.500   \n",
       "1290   M  57.0      116.772       1.569  34.126                        90.737   \n",
       "\n",
       "      Total Cholesterol (mg/dL)  HDL (mg/dL)  Fasting Blood Sugar (mg/dL)  \\\n",
       "675                       197.0        0.915                         99.0   \n",
       "1369                        NaN       82.000                        175.0   \n",
       "774                       106.0        6.809                        115.0   \n",
       "1044                      179.0       73.000                        132.0   \n",
       "1290                      254.0       60.000                        177.0   \n",
       "\n",
       "     Smoking Status Diabetes Status Physical Activity Level  \\\n",
       "675               N               Y                    High   \n",
       "1369              N               N                     Low   \n",
       "774               Y               Y                     Low   \n",
       "1044              N               N                     Low   \n",
       "1290              N               N                     Low   \n",
       "\n",
       "     Family History of CVD  Height (cm)  Waist-to-Height Ratio  Systolic BP  \\\n",
       "675                      N      178.000                  0.587        103.0   \n",
       "1369                     Y      199.458                  0.436        164.0   \n",
       "774                      N      187.000                  0.533          NaN   \n",
       "1044                     Y      178.000                  0.581        111.0   \n",
       "1290                     Y      156.854                  0.578        117.0   \n",
       "\n",
       "      Diastolic BP  Estimated LDL (mg/dL)  CVD Risk Score  \n",
       "675           99.0                    NaN          18.010  \n",
       "1369          90.0                  147.0          18.458  \n",
       "774           91.0                   33.0          16.530  \n",
       "1044          69.0                   76.0          15.930  \n",
       "1290         116.0                  164.0          17.755  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"CVD Risk Score\"\n",
    "cantNulos = df[target].isnull().sum()\n",
    "df = df.dropna(subset=[target])\n",
    "print(f\"Registros con Risk Score nulo eliminados: {cantNulos}\")\n",
    "\n",
    "antes = df.shape[0]\n",
    "df[\"Date of Service\"] = pd.to_datetime(df[\"Date of Service\"], errors=\"coerce\")\n",
    "df = df.sort_values([\"Patient ID\", \"Date of Service\"])\n",
    "df = df.drop_duplicates(subset=\"Patient ID\", keep=\"last\")\n",
    "desp = df.shape[0]\n",
    "print(f\"Duplicados eliminados: {antes - desp} (quedan {desp})\")\n",
    "\n",
    "\n",
    "df = df.drop([\"Patient ID\", \"Date of Service\", \n",
    "        \"Blood Pressure (mmHg)\", \"Blood Pressure Category\", \n",
    "        \"CVD Risk Level\"], axis =1)\n",
    "\n",
    "df[\"CVD Risk Score\"] = df[\"CVD Risk Score\"].clip(0, 100)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a52c4ed",
   "metadata": {},
   "source": [
    "## División del conjunto de datos\n",
    "\n",
    "Para evaluar adecuadamente la capacidad de generalización de los modelos, el dataset será dividido en Conjunto de entrenamiento (75%) y Conjunto de prueba (25%)\n",
    "\n",
    "El conjunto de entrenamiento se utilizará para el ajuste de modelos y la búsqueda de hiperparámetros.\n",
    "\n",
    "El conjunto de prueba se utilizará al final para evaluar el desempeño del modelo que seleccionems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5bcbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18b1729c",
   "metadata": {},
   "source": [
    "## 1. Modelo de regresión polinomial\n",
    "La regresión polinomial permite modelar relaciones no lineales mediante la expansión de las variables originales en términos de mayor grado.\n",
    "\n",
    "1. Preprocesamiento\n",
    "2. Generación de características polinomiales\n",
    "3. Modelo de regresión lineal\n",
    "\n",
    "Con GridSearchCV para explorar los diferentes grados del polinomio y distintas estrategias de escalamiento\n",
    "\n",
    "El desempeño será evaluado mediante los mismos parametros: RMSE, MAE y R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc84f37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e89b0647",
   "metadata": {},
   "source": [
    "## 2. Curvas de validación\n",
    "Para analizar el impacto de la complejidad, se generarán curvas de validación que muestren cómo varía el error en función del grado del polinomio.\n",
    "Se grafica el rrror promedio en validación cruzada y la desviación estándar del error\n",
    "El objetivo es identificarel puunto de mínima generalización, la evidencia de sobreajuste y la relación entre complejidad y estabilidad,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e854727c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f9dfa90",
   "metadata": {},
   "source": [
    "## 3. Modelos de regresión regularizados\n",
    "\n",
    "La regularización son para controlar la magnitud de los coeficientes y reducir el sobreajuste.\n",
    "Se usaran las tecnicas Ridge y Lasso\n",
    "\n",
    "Se utilizará GridSearchCV para buscar diferentes valores del parámetro de penalización y estrategias de escalamiento\n",
    "\n",
    "El análisis incluirá:\n",
    "- Comparación de métricas\n",
    "- Evaluación de estabilidad\n",
    "- Análisis de magnitud de coeficientes\n",
    "- Identificación de variables eliminadas por Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378bc246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4a3fceb",
   "metadata": {},
   "source": [
    "## 4. Modelo polinomial regularizado\n",
    "\n",
    "En esta sección se hara la generación de características polinomiales y la regularización.\n",
    "Se explorarán simultáneamente los grados del polinomio, los parámetro de penalización y una estrategia para escalar.\n",
    "El objetivo es evaluar si la regularización permite controlar el sobreajuste generado por el aumento en la complejidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf4c120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b0a4d5a",
   "metadata": {},
   "source": [
    "## 5. Comparación y selección del mejor modelo\n",
    "\n",
    "Haremos una tabla comparando: RMSE, MAE y R² y basados en los datos explicaremos cual es el mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce9736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67c54b4c",
   "metadata": {},
   "source": [
    "## 6. Construcción de ntervalos de confianza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc065450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd0bdd64",
   "metadata": {},
   "source": [
    "## 7. Análisis de resultados\n",
    "\n",
    "### Análisis cuantitativo:\n",
    "\n",
    "- ¿Cuál modelo obtuvo el mejor desempeño en test?\n",
    "- ¿Coincide con el mejor promedio en validación cruzada?\n",
    "- ¿El modelo con mejor promedio es necesariamente el más adecuado?\n",
    "- ¿Cómo cambia el error con la complejidad?\n",
    "- ¿Cómo afecta la regularización la estabilidad de los coeficientes?\n",
    "- ¿Los intervalos de confianza sugieren estabilidad o alta variabilidad?\n",
    "\n",
    "### Análisis cualitativo:\n",
    "\n",
    "- Variables seleccionadas por Lasso.\n",
    "- Interpretación práctica de los coeficientes.\n",
    "- Diferencias entre precisión e interpretabilidad.\n",
    "- Implicaciones estratégicas para AlpesHearth.\n",
    "- Si mayor complejidad implica mayor valor organizacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091f7224",
   "metadata": {},
   "source": [
    "## 8. Reflexión conceptual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9940e32",
   "metadata": {},
   "source": [
    "## 9. Uso de IA generativa\n",
    "\n",
    "Durante el desarrollo del laboratorio usamos modelos de IA generativa como herramienta de apoyo conceptual y para la estructuración del notebook.\n",
    "\n",
    "Las decisiones de modificacion de datos y construccion de modelps, la interpretación de los resultados y los analisis fueron realizadas por el equipo, unicamente usando inteligencia artificial para confirmar conceptos o estructurar adecuadamente elementos repetitivos en los bloques de codigo para ahorrar tiempo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyomo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
